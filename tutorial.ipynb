{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "['elle est chanceuse', 'she is lucky']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "        print(\"Input: \", input_tensor.shape)\n",
    "        print(\"Target: \", target_tensor.shape)\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "        print(\"Decoder output: \", decoder_outputs.shape, \"\\n\")\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n",
      "Decoder output:  torch.Size([32, 10, 2991]) \n",
      "\n",
      "Input:  torch.Size([32, 10])\n",
      "Target:  torch.Size([32, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb Cell 15\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m encoder \u001b[39m=\u001b[39m EncoderRNN(input_lang\u001b[39m.\u001b[39mn_words, hidden_size)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m decoder \u001b[39m=\u001b[39m AttnDecoderRNN(hidden_size, output_lang\u001b[39m.\u001b[39mn_words)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train(train_dataloader, encoder, decoder, \u001b[39m80\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, plot_every\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mNLLLoss()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     print_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     plot_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "\u001b[1;32m/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m encoder_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m decoder_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m encoder_outputs, encoder_hidden \u001b[39m=\u001b[39m encoder(input_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m decoder_outputs, _, _ \u001b[39m=\u001b[39m decoder(encoder_outputs, encoder_hidden, target_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDecoder output: \u001b[39m\u001b[39m\"\u001b[39m, decoder_outputs\u001b[39m.\u001b[39mshape, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(\u001b[39minput\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(embedded)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/tutorial.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output, hidden\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1101\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m   1103\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m   1106\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
