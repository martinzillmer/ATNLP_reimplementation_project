{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jump, opposite, right, twice, and, turn, oppo...</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[run, opposite, left, after, walk, right, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[walk, after, run, around, right, twice, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[look, around, right, thrice, and, turn, left,...</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[walk, opposite, left, twice, and, walk, oppos...</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  IN  \\\n",
       "0  [jump, opposite, right, twice, and, turn, oppo...   \n",
       "1   [run, opposite, left, after, walk, right, <eos>]   \n",
       "2    [walk, after, run, around, right, twice, <eos>]   \n",
       "3  [look, around, right, thrice, and, turn, left,...   \n",
       "4  [walk, opposite, left, twice, and, walk, oppos...   \n",
       "\n",
       "                                                 OUT  \n",
       "0  [<sos>, I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_...  \n",
       "1  [<sos>, I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_T...  \n",
       "2  [<sos>, I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_R...  \n",
       "3  [<sos>, I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_...  \n",
       "4  [<sos>, I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TU...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import get_dataframes\n",
    "train_url = \"https://raw.githubusercontent.com/brendenlake/SCAN/master/simple_split/tasks_train_simple.txt\"\n",
    "test_url = \"https://raw.githubusercontent.com/brendenlake/SCAN/master/simple_split/tasks_test_simple.txt\"\n",
    "train_df, test_df = get_dataframes(train_url, test_url)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<sos>': 0, '<eos>': 1, 'jump': 2, 'opposite': 3, 'right': 4, 'twice': 5, 'and': 6, 'turn': 7, 'thrice': 8, 'run': 9, 'left': 10, 'after': 11, 'walk': 12, 'around': 13, 'look': 14}\n",
      "{'<sos>': 0, '<eos>': 1, 'I_TURN_RIGHT': 2, 'I_JUMP': 3, 'I_WALK': 4, 'I_TURN_LEFT': 5, 'I_RUN': 6, 'I_LOOK': 7}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>OUT</th>\n",
       "      <th>IN_idx</th>\n",
       "      <th>OUT_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jump, opposite, right, twice, and, turn, oppo...</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_...</td>\n",
       "      <td>[tensor(2), tensor(3), tensor(4), tensor(5), t...</td>\n",
       "      <td>[tensor(0), tensor(2), tensor(2), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[run, opposite, left, after, walk, right, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_T...</td>\n",
       "      <td>[tensor(9), tensor(3), tensor(10), tensor(11),...</td>\n",
       "      <td>[tensor(0), tensor(2), tensor(4), tensor(5), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[walk, after, run, around, right, twice, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_R...</td>\n",
       "      <td>[tensor(12), tensor(11), tensor(9), tensor(13)...</td>\n",
       "      <td>[tensor(0), tensor(2), tensor(6), tensor(2), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[look, around, right, thrice, and, turn, left,...</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_...</td>\n",
       "      <td>[tensor(14), tensor(13), tensor(4), tensor(8),...</td>\n",
       "      <td>[tensor(0), tensor(2), tensor(7), tensor(2), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[walk, opposite, left, twice, and, walk, oppos...</td>\n",
       "      <td>[&lt;sos&gt;, I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TU...</td>\n",
       "      <td>[tensor(12), tensor(3), tensor(10), tensor(5),...</td>\n",
       "      <td>[tensor(0), tensor(5), tensor(5), tensor(4), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  IN  \\\n",
       "0  [jump, opposite, right, twice, and, turn, oppo...   \n",
       "1   [run, opposite, left, after, walk, right, <eos>]   \n",
       "2    [walk, after, run, around, right, twice, <eos>]   \n",
       "3  [look, around, right, thrice, and, turn, left,...   \n",
       "4  [walk, opposite, left, twice, and, walk, oppos...   \n",
       "\n",
       "                                                 OUT  \\\n",
       "0  [<sos>, I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_...   \n",
       "1  [<sos>, I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_T...   \n",
       "2  [<sos>, I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_R...   \n",
       "3  [<sos>, I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_...   \n",
       "4  [<sos>, I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TU...   \n",
       "\n",
       "                                              IN_idx  \\\n",
       "0  [tensor(2), tensor(3), tensor(4), tensor(5), t...   \n",
       "1  [tensor(9), tensor(3), tensor(10), tensor(11),...   \n",
       "2  [tensor(12), tensor(11), tensor(9), tensor(13)...   \n",
       "3  [tensor(14), tensor(13), tensor(4), tensor(8),...   \n",
       "4  [tensor(12), tensor(3), tensor(10), tensor(5),...   \n",
       "\n",
       "                                             OUT_idx  \n",
       "0  [tensor(0), tensor(2), tensor(2), tensor(3), t...  \n",
       "1  [tensor(0), tensor(2), tensor(4), tensor(5), t...  \n",
       "2  [tensor(0), tensor(2), tensor(6), tensor(2), t...  \n",
       "3  [tensor(0), tensor(2), tensor(7), tensor(2), t...  \n",
       "4  [tensor(0), tensor(5), tensor(5), tensor(4), t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import get_vocab\n",
    "\n",
    "train_vocab_in = get_vocab(train_df['IN'], 'in')\n",
    "train_vocab_out = get_vocab(train_df['OUT'], 'out')\n",
    "\n",
    "print(train_vocab_in.word2index)\n",
    "print(train_vocab_out.word2index)\n",
    "\n",
    "def series2idx(row):\n",
    "    x = train_vocab_in.col2idx(row, 'IN')\n",
    "    y = train_vocab_out.col2idx(row, 'OUT')\n",
    "    return x, y\n",
    "    \n",
    "train_df[['IN_idx','OUT_idx']] = train_df.apply(series2idx, axis=1, result_type='expand')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloading import Text_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create datasets\n",
    "training_data = Text_dataset(train_df[['IN_idx', 'OUT_idx']], True, 100000)\n",
    "#test_data = Text_dataset(test_df, False)\n",
    "\n",
    "# Define dataloaders\n",
    "bs = 1 # Batch size\n",
    "train_dataloader = DataLoader(training_data, batch_size=bs, shuffle=False)\n",
    "#test_dataloader = DataLoader(test_data, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 10,  8, 11,  2, 10,  8,  1]])\n",
      "tensor([[0, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    xs, ys = data\n",
    "    print(xs)\n",
    "    print(ys)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for dimension 1 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mEncoderRNN(train_vocab_in\u001b[38;5;241m.\u001b[39mn_words, hidden_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m decoder \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mDecoderRNN(hidden_size, train_vocab_out\u001b[38;5;241m.\u001b[39mn_words, device, max_len)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\45311\\kode\\ATNLP_reimplementation_project\\training.py:50\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dataloader, encoder, decoder, device, n_epochs, learning_rate, print_every, plot_every)\u001b[0m\n\u001b[0;32m     47\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     print_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     52\u001b[0m     plot_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\45311\\kode\\ATNLP_reimplementation_project\\training.py:19\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m encoder_outputs, encoder_hidden \u001b[38;5;241m=\u001b[39m encoder(input_tensor)\n\u001b[1;32m---> 19\u001b[0m decoder_outputs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\n\u001b[0;32m     22\u001b[0m     decoder_outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, decoder_outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     23\u001b[0m     target_tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\45311\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\45311\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\45311\\kode\\ATNLP_reimplementation_project\\models.py:45\u001b[0m, in \u001b[0;36mDecoderRNN.forward\u001b[1;34m(self, encoder_outputs, encoder_hidden, target_tensor)\u001b[0m\n\u001b[0;32m     41\u001b[0m decoder_outputs\u001b[38;5;241m.\u001b[39mappend(decoder_output)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Teacher forcing: Feed the target as the next input\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     decoder_input \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Teacher forcing\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Without teacher forcing: use its own predictions as the next input\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     _, topi \u001b[38;5;241m=\u001b[39m decoder_output\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 14 is out of bounds for dimension 1 with size 14"
     ]
    }
   ],
   "source": [
    "import models\n",
    "from training import train\n",
    "max_len = 30\n",
    "hidden_size = 200\n",
    "\n",
    "encoder = models.EncoderRNN(train_vocab_in.n_words, hidden_size).to(device)\n",
    "decoder = models.DecoderRNN(hidden_size, train_vocab_out.n_words, device, max_len).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
