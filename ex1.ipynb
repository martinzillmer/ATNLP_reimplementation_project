{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jump, opposite, right, twice, and, turn, oppo...</td>\n",
       "      <td>[I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[run, opposite, left, after, walk, right, &lt;eos...</td>\n",
       "      <td>[I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[walk, after, run, around, right, twice, &lt;eos&gt;...</td>\n",
       "      <td>[I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[look, around, right, thrice, and, turn, left,...</td>\n",
       "      <td>[I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[walk, opposite, left, twice, and, walk, oppos...</td>\n",
       "      <td>[I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  IN  \\\n",
       "0  [jump, opposite, right, twice, and, turn, oppo...   \n",
       "1  [run, opposite, left, after, walk, right, <eos...   \n",
       "2  [walk, after, run, around, right, twice, <eos>...   \n",
       "3  [look, around, right, thrice, and, turn, left,...   \n",
       "4  [walk, opposite, left, twice, and, walk, oppos...   \n",
       "\n",
       "                                                 OUT  \n",
       "0  [I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...  \n",
       "1  [I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...  \n",
       "2  [I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...  \n",
       "3  [I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...  \n",
       "4  [I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import get_dataframes\n",
    "train_url = \"https://raw.githubusercontent.com/brendenlake/SCAN/master/simple_split/tasks_train_simple.txt\"\n",
    "test_url = \"https://raw.githubusercontent.com/brendenlake/SCAN/master/simple_split/tasks_test_simple.txt\"\n",
    "train_df, test_df = get_dataframes(train_url, test_url)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'jump': 3, 'opposite': 4, 'right': 5, 'twice': 6, 'and': 7, 'turn': 8, 'thrice': 9, 'run': 10, 'left': 11, 'after': 12, 'walk': 13, 'around': 14, 'look': 15}\n",
      "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'I_TURN_RIGHT': 3, 'I_JUMP': 4, 'I_WALK': 5, 'I_TURN_LEFT': 6, 'I_RUN': 7, 'I_LOOK': 8}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>OUT</th>\n",
       "      <th>IN_idx</th>\n",
       "      <th>OUT_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jump, opposite, right, twice, and, turn, oppo...</td>\n",
       "      <td>[I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...</td>\n",
       "      <td>[tensor(3), tensor(4), tensor(5), tensor(6), t...</td>\n",
       "      <td>[tensor(3), tensor(3), tensor(4), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[run, opposite, left, after, walk, right, &lt;eos...</td>\n",
       "      <td>[I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...</td>\n",
       "      <td>[tensor(10), tensor(4), tensor(11), tensor(12)...</td>\n",
       "      <td>[tensor(3), tensor(5), tensor(6), tensor(6), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[walk, after, run, around, right, twice, &lt;eos&gt;...</td>\n",
       "      <td>[I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...</td>\n",
       "      <td>[tensor(13), tensor(12), tensor(10), tensor(14...</td>\n",
       "      <td>[tensor(3), tensor(7), tensor(3), tensor(7), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[look, around, right, thrice, and, turn, left,...</td>\n",
       "      <td>[I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...</td>\n",
       "      <td>[tensor(15), tensor(14), tensor(5), tensor(9),...</td>\n",
       "      <td>[tensor(3), tensor(8), tensor(3), tensor(8), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[walk, opposite, left, twice, and, walk, oppos...</td>\n",
       "      <td>[I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...</td>\n",
       "      <td>[tensor(13), tensor(4), tensor(11), tensor(6),...</td>\n",
       "      <td>[tensor(6), tensor(6), tensor(5), tensor(6), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  IN  \\\n",
       "0  [jump, opposite, right, twice, and, turn, oppo...   \n",
       "1  [run, opposite, left, after, walk, right, <eos...   \n",
       "2  [walk, after, run, around, right, twice, <eos>...   \n",
       "3  [look, around, right, thrice, and, turn, left,...   \n",
       "4  [walk, opposite, left, twice, and, walk, oppos...   \n",
       "\n",
       "                                                 OUT  \\\n",
       "0  [I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...   \n",
       "1  [I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...   \n",
       "2  [I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...   \n",
       "3  [I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...   \n",
       "4  [I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...   \n",
       "\n",
       "                                              IN_idx  \\\n",
       "0  [tensor(3), tensor(4), tensor(5), tensor(6), t...   \n",
       "1  [tensor(10), tensor(4), tensor(11), tensor(12)...   \n",
       "2  [tensor(13), tensor(12), tensor(10), tensor(14...   \n",
       "3  [tensor(15), tensor(14), tensor(5), tensor(9),...   \n",
       "4  [tensor(13), tensor(4), tensor(11), tensor(6),...   \n",
       "\n",
       "                                             OUT_idx  \n",
       "0  [tensor(3), tensor(3), tensor(4), tensor(3), t...  \n",
       "1  [tensor(3), tensor(5), tensor(6), tensor(6), t...  \n",
       "2  [tensor(3), tensor(7), tensor(3), tensor(7), t...  \n",
       "3  [tensor(3), tensor(8), tensor(3), tensor(8), t...  \n",
       "4  [tensor(6), tensor(6), tensor(5), tensor(6), t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import get_vocab\n",
    "\n",
    "train_vocab_in = get_vocab(train_df['IN'], 'in')\n",
    "train_vocab_out = get_vocab(train_df['OUT'], 'out')\n",
    "\n",
    "print(train_vocab_in.word2index)\n",
    "print(train_vocab_out.word2index)\n",
    "\n",
    "def series2idx(row):\n",
    "    x = train_vocab_in.col2idx(row, 'IN')\n",
    "    y = train_vocab_out.col2idx(row, 'OUT')\n",
    "    return x, y\n",
    "    \n",
    "train_df[['IN_idx','OUT_idx']] = train_df.apply(series2idx, axis=1, result_type='expand')\n",
    "test_df[['IN_idx','OUT_idx']] = test_df.apply(series2idx, axis=1, result_type='expand')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "from dataloading import Text_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utilities import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Create datasets\n",
    "training_data = Text_dataset(train_df[['IN_idx', 'OUT_idx']], True, 1000)\n",
    "test_data = Text_dataset(test_df[['IN_idx', 'OUT_idx']], False)\n",
    "\n",
    "# Define dataloaders\n",
    "bs = 1 # Batch size for training\n",
    "train_dataloader = DataLoader(training_data, batch_size=bs, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False) # We can evaluate in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1\n",
      "Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 35s (- 0m 0s) (1 100%) 0.6229\n",
      "Iteration 0: 155.15514874458313\n",
      "Random seed set as 1\n",
      "2m 26s (- 0m 0s) (1 100%) 0.6125\n",
      "Iteration 1: 146.9193799495697\n",
      "Random seed set as 2\n",
      "2m 28s (- 0m 0s) (1 100%) 0.6097\n",
      "Iteration 2: 148.3748700618744\n",
      "Random seed set as 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/ex1.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/ex1.ipynb#X41sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m encoder \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcompile(models\u001b[39m.\u001b[39mEncoderRNN(\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m, train_vocab_in\u001b[39m.\u001b[39mn_words, hidden_size, layers, dropout)\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/ex1.ipynb#X41sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m decoder \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcompile(models\u001b[39m.\u001b[39mDecoderRNN(\u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m, hidden_size, train_vocab_out\u001b[39m.\u001b[39mn_words, layers, device, max_len)\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/ex1.ipynb#X41sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train(train_dataloader, encoder, decoder, device, save_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mex1_best_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(i))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/ex1.ipynb#X41sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m a \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martin/kode/kurser/ATNLP/ATNLP_reimplementation_project/ex1.ipynb#X41sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIteration \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i,a\u001b[39m-\u001b[39mb))\n",
      "File \u001b[0;32m~/kode/kurser/ATNLP/ATNLP_reimplementation_project/training.py:64\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, encoder, decoder, device, n_epochs, learning_rate, print_every, plot_every, save_name)\u001b[0m\n\u001b[1;32m     61\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mNLLLoss()\n\u001b[1;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     loss \u001b[39m=\u001b[39m train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, device)\n\u001b[1;32m     65\u001b[0m     print_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     66\u001b[0m     plot_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "File \u001b[0;32m~/kode/kurser/ATNLP/ATNLP_reimplementation_project/training.py:29\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     target_tensor_decoder \u001b[39m=\u001b[39m target_tensor\n\u001b[0;32m---> 29\u001b[0m decoder_outputs, _, _ \u001b[39m=\u001b[39m decoder(encoder_outputs, encoder_hidden, target_tensor_decoder)\n\u001b[1;32m     31\u001b[0m loss \u001b[39m=\u001b[39m criterion(\n\u001b[1;32m     32\u001b[0m     decoder_outputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, decoder_outputs\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)),\n\u001b[1;32m     33\u001b[0m     target_tensor\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:328\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    327\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    329\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/kode/kurser/ATNLP/ATNLP_reimplementation_project/models.py:64\u001b[0m, in \u001b[0;36mDecoderRNN.forward\u001b[0;34m(self, encoder_outputs, encoder_hidden, target_tensor)\u001b[0m\n\u001b[1;32m     61\u001b[0m decoder_outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_len):\n\u001b[0;32m---> 64\u001b[0m     decoder_output, decoder_hidden  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_step(decoder_input, decoder_hidden)\n\u001b[1;32m     65\u001b[0m     decoder_outputs\u001b[39m.\u001b[39mappend(decoder_output)\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m target_tensor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[39m# Teacher forcing: Feed the target as the next input\u001b[39;00m\n",
      "File \u001b[0;32m~/kode/kurser/ATNLP/ATNLP_reimplementation_project/models.py:82\u001b[0m, in \u001b[0;36mDecoderRNN.forward_step\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     80\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(\u001b[39minput\u001b[39m)\n\u001b[1;32m     81\u001b[0m output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(output)\n\u001b[0;32m---> 82\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(output, hidden)\n\u001b[1;32m     83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(output)\n\u001b[1;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m output, hidden\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:894\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    892\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msqueeze(batch_dim)\n\u001b[1;32m    893\u001b[0m     hidden \u001b[39m=\u001b[39m (hidden[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m), hidden[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 894\u001b[0m \u001b[39mreturn\u001b[39;00m output, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpermute_hidden(hidden, unsorted_indices)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:797\u001b[0m, in \u001b[0;36mLSTM.permute_hidden\u001b[0;34m(self, hx, permutation)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    794\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    796\u001b[0m \u001b[39m# Same as above, see torch/nn/modules/module.py::_forward_unimplemented\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpermute_hidden\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    798\u001b[0m                    hx: Tuple[Tensor, Tensor],\n\u001b[1;32m    799\u001b[0m                    permutation: Optional[Tensor]\n\u001b[1;32m    800\u001b[0m                    ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[1;32m    801\u001b[0m     \u001b[39mif\u001b[39;00m permutation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m         \u001b[39mreturn\u001b[39;00m hx\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import models\n",
    "import time\n",
    "from training import train\n",
    "\n",
    "\n",
    "# Best in experiment 1\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "\n",
    "for i in range(5):\n",
    "    set_seed(i)\n",
    "    encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "    decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)      \n",
    "    train(train_dataloader, encoder, decoder, device, save_name='ex1_best_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall best\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0.5\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "\n",
    "for i in range(5):\n",
    "    set_seed(i)\n",
    "    encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "    decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)\n",
    "    train(train_dataloader, encoder, decoder, device, save_name='ex1_overall_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from training import evaluate\n",
    "# Overall best\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0.5\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "\n",
    "acc = 0\n",
    "for i in range(1,6):\n",
    "    encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "    decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)\n",
    "    encoder.load_state_dict(torch.load('models/encoder_ex1_best_'+str(i)+'.pth'))\n",
    "    decoder.load_state_dict(torch.load('models/decoder_ex1_best_'+str(i)+'.pth'))\n",
    "    acc += evaluate(encoder, decoder, test_dataloader, device)\n",
    "\n",
    "print(acc/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "acc = evaluate(encoder, decoder, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best overall\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0.5\n",
    "\n",
    "bs = 1 # Batch size\n",
    "\n",
    "percentages = [0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64]\n",
    "replications = 5\n",
    "accurcies = torch.zeros(len(percentages), replications)\n",
    "for i, p in enumerate(percentages):\n",
    "    set_seed(42)\n",
    "\n",
    "    idx = int((len(train_df) + len(test_df)) * p)\n",
    "    training_data = Text_dataset(train_df[['IN_idx', 'OUT_idx']][:idx], True, 100000)\n",
    "    \n",
    "    for j in range(replications):\n",
    "            set_seed(i)\n",
    "            encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "            decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)\n",
    "            train_dataloader = DataLoader(training_data, batch_size=bs, shuffle=False)\n",
    "            name = 'ex1_pt2_p'+str(p)[2:]+'_'+str(j)\n",
    "            train(train_dataloader, encoder, decoder, device, save_name=name)\n",
    "            acc = evaluate(encoder, decoder, test_dataloader, device)\n",
    "            accurcies[i,j] = acc\n",
    "\n",
    "txt = str(accurcies)\n",
    "f = open(\"ex1_pt2.txt\", \"a\")\n",
    "f.write(txt)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
