{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jump, opposite, right, twice, and, turn, oppo...</td>\n",
       "      <td>[I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[run, opposite, left, after, walk, right, &lt;eos...</td>\n",
       "      <td>[I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[walk, after, run, around, right, twice, &lt;eos&gt;...</td>\n",
       "      <td>[I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[look, around, right, thrice, and, turn, left,...</td>\n",
       "      <td>[I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[walk, opposite, left, twice, and, walk, oppos...</td>\n",
       "      <td>[I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  IN  \\\n",
       "0  [jump, opposite, right, twice, and, turn, oppo...   \n",
       "1  [run, opposite, left, after, walk, right, <eos...   \n",
       "2  [walk, after, run, around, right, twice, <eos>...   \n",
       "3  [look, around, right, thrice, and, turn, left,...   \n",
       "4  [walk, opposite, left, twice, and, walk, oppos...   \n",
       "\n",
       "                                                 OUT  \n",
       "0  [I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...  \n",
       "1  [I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...  \n",
       "2  [I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...  \n",
       "3  [I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...  \n",
       "4  [I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import get_dataframes\n",
    "train_url = \"https://raw.githubusercontent.com/brendenlake/SCAN/master/simple_split/tasks_train_simple.txt\"\n",
    "test_url = \"https://raw.githubusercontent.com/brendenlake/SCAN/master/simple_split/tasks_test_simple.txt\"\n",
    "train_df, test_df = get_dataframes(train_url, test_url)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'jump': 3, 'opposite': 4, 'right': 5, 'twice': 6, 'and': 7, 'turn': 8, 'thrice': 9, 'run': 10, 'left': 11, 'after': 12, 'walk': 13, 'around': 14, 'look': 15}\n",
      "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'I_TURN_RIGHT': 3, 'I_JUMP': 4, 'I_WALK': 5, 'I_TURN_LEFT': 6, 'I_RUN': 7, 'I_LOOK': 8}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>OUT</th>\n",
       "      <th>IN_idx</th>\n",
       "      <th>OUT_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jump, opposite, right, twice, and, turn, oppo...</td>\n",
       "      <td>[I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...</td>\n",
       "      <td>[tensor(3), tensor(4), tensor(5), tensor(6), t...</td>\n",
       "      <td>[tensor(3), tensor(3), tensor(4), tensor(3), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[run, opposite, left, after, walk, right, &lt;eos...</td>\n",
       "      <td>[I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...</td>\n",
       "      <td>[tensor(10), tensor(4), tensor(11), tensor(12)...</td>\n",
       "      <td>[tensor(3), tensor(5), tensor(6), tensor(6), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[walk, after, run, around, right, twice, &lt;eos&gt;...</td>\n",
       "      <td>[I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...</td>\n",
       "      <td>[tensor(13), tensor(12), tensor(10), tensor(14...</td>\n",
       "      <td>[tensor(3), tensor(7), tensor(3), tensor(7), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[look, around, right, thrice, and, turn, left,...</td>\n",
       "      <td>[I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...</td>\n",
       "      <td>[tensor(15), tensor(14), tensor(5), tensor(9),...</td>\n",
       "      <td>[tensor(3), tensor(8), tensor(3), tensor(8), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[walk, opposite, left, twice, and, walk, oppos...</td>\n",
       "      <td>[I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...</td>\n",
       "      <td>[tensor(13), tensor(4), tensor(11), tensor(6),...</td>\n",
       "      <td>[tensor(6), tensor(6), tensor(5), tensor(6), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  IN  \\\n",
       "0  [jump, opposite, right, twice, and, turn, oppo...   \n",
       "1  [run, opposite, left, after, walk, right, <eos...   \n",
       "2  [walk, after, run, around, right, twice, <eos>...   \n",
       "3  [look, around, right, thrice, and, turn, left,...   \n",
       "4  [walk, opposite, left, twice, and, walk, oppos...   \n",
       "\n",
       "                                                 OUT  \\\n",
       "0  [I_TURN_RIGHT, I_TURN_RIGHT, I_JUMP, I_TURN_RI...   \n",
       "1  [I_TURN_RIGHT, I_WALK, I_TURN_LEFT, I_TURN_LEF...   \n",
       "2  [I_TURN_RIGHT, I_RUN, I_TURN_RIGHT, I_RUN, I_T...   \n",
       "3  [I_TURN_RIGHT, I_LOOK, I_TURN_RIGHT, I_LOOK, I...   \n",
       "4  [I_TURN_LEFT, I_TURN_LEFT, I_WALK, I_TURN_LEFT...   \n",
       "\n",
       "                                              IN_idx  \\\n",
       "0  [tensor(3), tensor(4), tensor(5), tensor(6), t...   \n",
       "1  [tensor(10), tensor(4), tensor(11), tensor(12)...   \n",
       "2  [tensor(13), tensor(12), tensor(10), tensor(14...   \n",
       "3  [tensor(15), tensor(14), tensor(5), tensor(9),...   \n",
       "4  [tensor(13), tensor(4), tensor(11), tensor(6),...   \n",
       "\n",
       "                                             OUT_idx  \n",
       "0  [tensor(3), tensor(3), tensor(4), tensor(3), t...  \n",
       "1  [tensor(3), tensor(5), tensor(6), tensor(6), t...  \n",
       "2  [tensor(3), tensor(7), tensor(3), tensor(7), t...  \n",
       "3  [tensor(3), tensor(8), tensor(3), tensor(8), t...  \n",
       "4  [tensor(6), tensor(6), tensor(5), tensor(6), t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import get_vocab\n",
    "\n",
    "train_vocab_in = get_vocab(train_df['IN'], 'in')\n",
    "train_vocab_out = get_vocab(train_df['OUT'], 'out')\n",
    "\n",
    "print(train_vocab_in.word2index)\n",
    "print(train_vocab_out.word2index)\n",
    "\n",
    "def series2idx(row):\n",
    "    x = train_vocab_in.col2idx(row, 'IN')\n",
    "    y = train_vocab_out.col2idx(row, 'OUT')\n",
    "    return x, y\n",
    "    \n",
    "train_df[['IN_idx','OUT_idx']] = train_df.apply(series2idx, axis=1, result_type='expand')\n",
    "test_df[['IN_idx','OUT_idx']] = test_df.apply(series2idx, axis=1, result_type='expand')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "from dataloading import Text_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utilities import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Create datasets\n",
    "training_data = Text_dataset(train_df[['IN_idx', 'OUT_idx']], True, 1000)\n",
    "test_data = Text_dataset(test_df[['IN_idx', 'OUT_idx']], False)\n",
    "\n",
    "# Define dataloaders\n",
    "bs = 1 # Batch size for training\n",
    "train_dataloader = DataLoader(training_data, batch_size=bs, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False) # We can evaluate in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:39, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 40s (- 0m 0s) (1 100%) 0.6260\n",
      "Random seed set as 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:39, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 39s (- 0m 0s) (1 100%) 0.6103\n",
      "Random seed set as 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:39, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 39s (- 0m 0s) (1 100%) 0.6133\n",
      "Random seed set as 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:39, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 39s (- 0m 0s) (1 100%) 0.6007\n",
      "Random seed set as 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:39, 25.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 39s (- 0m 0s) (1 100%) 0.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import models\n",
    "from training import train\n",
    "\n",
    "\n",
    "# Best in experiment 1\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "\n",
    "for i in range(5):\n",
    "    set_seed(i)\n",
    "    if not sys.platform == \"win32\":\n",
    "        encoder = torch.compile(models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device))\n",
    "        decoder = torch.compile(models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device))\n",
    "    else:\n",
    "        encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "        decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)      \n",
    "    train(train_dataloader, encoder, decoder, device, save_name='ex1_best_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:39, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 39s (- 0m 0s) (1 100%) 0.6348\n",
      "Random seed set as 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "726it [00:29, 24.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m encoder \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mEncoderRNN(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m, train_vocab_in\u001b[38;5;241m.\u001b[39mn_words, hidden_size, layers, dropout)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m decoder \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mDecoderRNN(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m, hidden_size, train_vocab_out\u001b[38;5;241m.\u001b[39mn_words, layers, device, max_len)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mex1_overall_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\45311\\kode\\ATNLP_reimplementation_project\\training.py:63\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dataloader, encoder, decoder, device, n_epochs, learning_rate, print_every, plot_every, save_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 63\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     print_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     65\u001b[0m     plot_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\45311\\kode\\ATNLP_reimplementation_project\\training.py:28\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     target_tensor_decoder \u001b[38;5;241m=\u001b[39m target_tensor\n\u001b[1;32m---> 28\u001b[0m decoder_outputs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor_decoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\n\u001b[0;32m     31\u001b[0m     decoder_outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, decoder_outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     32\u001b[0m     target_tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\45311\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\45311\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\45311\\kode\\ATNLP_reimplementation_project\\models.py:64\u001b[0m, in \u001b[0;36mDecoderRNN.forward\u001b[1;34m(self, encoder_outputs, encoder_hidden, target_tensor)\u001b[0m\n\u001b[0;32m     61\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len):\n\u001b[1;32m---> 64\u001b[0m     decoder_output, decoder_hidden  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     decoder_outputs\u001b[38;5;241m.\u001b[39mappend(decoder_output)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# Teacher forcing: Feed the target as the next input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\45311\\kode\\ATNLP_reimplementation_project\\models.py:81\u001b[0m, in \u001b[0;36mDecoderRNN.forward_step\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, hidden):\n\u001b[0;32m     80\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(output, hidden)\n\u001b[0;32m     83\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(output)\n",
      "File \u001b[1;32mc:\\Users\\45311\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\nn\\functional.py:1471\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Overall best\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0.5\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "\n",
    "for i in range(5):\n",
    "    set_seed(i)\n",
    "    encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "    decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)\n",
    "    train(train_dataloader, encoder, decoder, device, save_name='ex1_overall_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from training import evaluate\n",
    "# Overall best\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0.5\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "\n",
    "acc = 0\n",
    "for i in range(1,6):\n",
    "    encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "    decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)\n",
    "    encoder.load_state_dict(torch.load('models/encoder_ex1_best_'+str(i)+'.pth'))\n",
    "    decoder.load_state_dict(torch.load('models/decoder_ex1_best_'+str(i)+'.pth'))\n",
    "    acc += evaluate(encoder, decoder, test_dataloader, device)\n",
    "\n",
    "print(acc/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "acc = evaluate(encoder, decoder, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best overall\n",
    "max_len = train_df.OUT_idx.apply(len).max()\n",
    "layers = 2\n",
    "hidden_size = 200\n",
    "dropout = 0.5\n",
    "\n",
    "bs = 1 # Batch size\n",
    "\n",
    "percentages = [0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64]\n",
    "replications = 5\n",
    "accurcies = torch.zeros(len(percentages), replications)\n",
    "for i, p in enumerate(percentages):\n",
    "    set_seed(42)\n",
    "\n",
    "    idx = int(len(train_df) * p)\n",
    "    training_data = Text_dataset(train_df[['IN_idx', 'OUT_idx']][:idx], True, 100000)\n",
    "    \n",
    "    for j in range(replications):\n",
    "            set_seed(i)\n",
    "            encoder = models.EncoderRNN('lstm', train_vocab_in.n_words, hidden_size, layers, dropout).to(device)\n",
    "            decoder = models.DecoderRNN('lstm', hidden_size, train_vocab_out.n_words, layers, device, max_len).to(device)\n",
    "            train_dataloader = DataLoader(training_data, batch_size=bs, shuffle=False)\n",
    "            name = 'ex1_pt2_p'+str(p)[2:]+'_'+str(j)\n",
    "            train(train_dataloader, encoder, decoder, device, save_name=name)\n",
    "            acc = evaluate(encoder, decoder, test_dataloader, device)\n",
    "            accurcies[i,j] = acc\n",
    "\n",
    "txt = str(accurcies)\n",
    "f = open(\"ex1_pt2.txt\", \"a\")\n",
    "f.write(txt)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
